#!/usr/bin/env python3
"""
ë…¼ë¬¸ ë°©ë²•ë¡  ì •í™•íˆ ë”°ë¥´ê¸° - PrRSMDD-ADRD ìƒì„±

Nature Mental Health 2025 ë…¼ë¬¸ Methods (885-886í˜ì´ì§€)ë¥¼ ì •í™•íˆ ë”°ë¼:
1. Inverse Normal Transformation (INT)
2. Prevalent Case ì œê±°
3. 10-fold CV + 1SE ruleë¡œ LASSO alpha ì„ íƒ
4. Cox LASSO Regressionìœ¼ë¡œ ProtRS ìƒì„±
5. C-index í‰ê°€

í•µì‹¬ ê°œì„ ì‚¬í•­:
- participant.p42018 ì‚¬ìš© (11,616ê°œ ì¼€ì´ìŠ¤, ê¸°ì¡´ë³´ë‹¤ 6.8ë°° ë§ìŒ)
- Prevalent case ì œê±° (baseline ì´ì „ ì¹˜ë§¤)
- ì •í™•í•œ Time/Event ê³„ì‚°
"""

import pandas as pd
import numpy as np
from scipy import stats
from sklearn.model_selection import train_test_split, KFold
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sksurv.linear_model import CoxnetSurvivalAnalysis
from sksurv.util import Surv
from sksurv.metrics import concordance_index_censored
import matplotlib.pyplot as plt
try:
    import seaborn as sns
    sns.set_style("whitegrid")
except ImportError:
    sns = None
import warnings
warnings.filterwarnings('ignore')

# ê²½ë¡œ ì„¤ì •
import os
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MASTER = os.path.join(BASE_DIR, "data/ukb/ukb_usable_master.parquet")
OUTCOME_FILE = os.path.join(BASE_DIR, "data/ukb/ukb_cog_cov_master_plus_dementia_outcome.csv")
OUT_PROTRS = os.path.join(BASE_DIR, "data/protrs_paper_method.parquet")
OUT_PLOT = os.path.join(BASE_DIR, "data/protrs_paper_method_performance.png")
OUT_WEIGHTS = os.path.join(BASE_DIR, "data/protrs_paper_method_weights.csv")

def apply_inverse_normal_transform(X):
    """
    Inverse Normal Transformation (INT)
    ë…¼ë¬¸: "We applied the inverse normal transformation to individual proteins 
    (n=2,920) in the baseline cohort to correct distributional skewness and 
    unify the scales into z scores"
    
    Args:
        X: ë‹¨ë°±ì§ˆ ë°ì´í„° (n_samples, n_features)
    
    Returns:
        X_int: INT ë³€í™˜ëœ ë°ì´í„° (Z-scores)
    """
    X_int = np.zeros_like(X)
    
    for i in range(X.shape[1]):
        col = X[:, i]
        # ê²°ì¸¡ì¹˜ ì œì™¸í•˜ê³  rank ê³„ì‚°
        valid_mask = ~np.isnan(col)
        if valid_mask.sum() == 0:
            X_int[:, i] = col
            continue
        
        valid_col = col[valid_mask]
        n_valid = len(valid_col)
        
        # Rank ê³„ì‚° (tie ì²˜ë¦¬: average)
        ranks = stats.rankdata(valid_col, method='average')
        
        # INT ì ìš©: (rank - 0.5) / n -> norm.ppf
        transformed = stats.norm.ppf((ranks - 0.5) / n_valid)
        
        # ì›ë˜ ìœ„ì¹˜ì— ë³µì›
        X_int[valid_mask, i] = transformed
        X_int[~valid_mask, i] = np.nan
    
    return X_int

def get_protein_cols(df):
    """ë‹¨ë°±ì§ˆ ì»¬ëŸ¼ ì¶”ì¶œ (ë‚ ì§œ ì»¬ëŸ¼ ì œì™¸)"""
    exclude_cols = [
        "eid", "sex", "target_age", "target_dementia", "participant.p42018",
        "time", "event", "baseline_date", "censor_date", "dementia_date",
        "baseline", "dementia_date", "death_date", "is_prevalent",
        "event_calc", "time_calc"
    ]
    
    # ë‚ ì§œ íƒ€ì… ì»¬ëŸ¼ë„ ì œì™¸
    date_cols = []
    for col in df.columns:
        if pd.api.types.is_datetime64_any_dtype(df[col]):
            date_cols.append(col)
    
    return [
        c for c in df.columns
        if c not in exclude_cols
        and c not in date_cols
        and not c.startswith("pc__")
        and not c.startswith("assess__")
        and not c.startswith("online__")
    ]

def calculate_survival_time_paper_method(df, baseline_date_col=None, death_date_col=None):
    """
    ë…¼ë¬¸ ë°©ì‹ Time/Event ê³„ì‚°
    
    í•µì‹¬:
    1. Prevalent case ì œê±° (baseline ì´ì „ ì¹˜ë§¤)
    2. Event: participant.p42018 ì¡´ì¬ ì—¬ë¶€
    3. Time: baselineë¶€í„° dementia_date ë˜ëŠ” censor_dateê¹Œì§€
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        baseline_date_col: baseline date ì»¬ëŸ¼ëª… (ì—†ìœ¼ë©´ ì¶”ì •)
        death_date_col: death date ì»¬ëŸ¼ëª… (ì—†ìœ¼ë©´ ì‚¬ìš© ì•ˆ í•¨)
    
    Returns:
        df with 'time', 'event', 'is_prevalent' columns
    """
    df = df.copy()
    
    # ë‚ ì§œ ë³€í™˜
    if 'participant.p42018' in df.columns:
        dementia_date = pd.to_datetime(df['participant.p42018'], errors='coerce')
    else:
        dementia_date = None
    
    # Baseline date (ê°•í™”ëœ fallback ë¡œì§)
    baseline = None
    
    # 1. ì§€ì •ëœ ì»¬ëŸ¼ ì‚¬ìš©
    if baseline_date_col and baseline_date_col in df.columns:
        print(f"   âœ… ì§€ì •ëœ ì»¬ëŸ¼ ì‚¬ìš©: {baseline_date_col}")
        baseline = pd.to_datetime(df[baseline_date_col], errors='coerce')
    
    # 2. ìë™ ê²€ìƒ‰: ì—¬ëŸ¬ í›„ë³´ ì»¬ëŸ¼ ì‹œë„
    elif 'f.53.0.0' in df.columns:
        print("   âœ… 'f.53.0.0' ì»¬ëŸ¼ ìë™ ê°ì§€ ë° ì‚¬ìš©")
        baseline = pd.to_datetime(df['f.53.0.0'], errors='coerce')
    elif 'p53_i0' in df.columns:
        print("   âœ… 'p53_i0' ì»¬ëŸ¼ ìë™ ê°ì§€ ë° ì‚¬ìš©")
        baseline = pd.to_datetime(df['p53_i0'], errors='coerce')
    elif 'date_attending' in df.columns:
        print("   âœ… 'date_attending' ì»¬ëŸ¼ ìë™ ê°ì§€ ë° ì‚¬ìš©")
        baseline = pd.to_datetime(df['date_attending'], errors='coerce')
    
    # ì£¼ì˜: assess__p20023_i0ì€ ë°˜ì‘ì†ë„(ms)ì´ë¯€ë¡œ ë‚ ì§œ ê³„ì‚°ì— ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    # elif 'assess__p20023_i0' in df.columns:
    #     # ì´ ë¶€ë¶„ì€ ì‚­ì œë¨: p20023ì€ ë‚ ì§œê°€ ì•„ë‹ˆë¼ ë°˜ì‘ì†ë„(ms)ì…ë‹ˆë‹¤
    
    # 3. ë‚˜ì´ ê¸°ë°˜ ì—­ì‚° ì‹œë„ (p21003_i0 + p34)
    if baseline is None or baseline.isna().all():
        if 'target_age' in df.columns and 'p34' in df.columns:
            print("   âš ï¸  ë‚˜ì´ ê¸°ë°˜ ì—­ì‚° ì‹œë„...")
            # Year of birth + Age = Year of recruitment
            year_birth = pd.to_datetime(df['p34'], format='%Y', errors='coerce').dt.year
            age = df['target_age']
            year_recruit = year_birth + age
            # í•´ë‹¹ ë…„ë„ì˜ ì¤‘ê°„ ë‚ ì§œë¡œ ì„¤ì • (6ì›” 15ì¼)
            baseline = pd.to_datetime(year_recruit.astype(str) + '-06-15', errors='coerce')
            if baseline.notna().sum() > 0:
                print(f"   âœ… ë‚˜ì´ ê¸°ë°˜ ì—­ì‚° ì„±ê³µ: {baseline.notna().sum():,}ê°œ")
            else:
                baseline = None
    
    # 4. ìµœí›„ì˜ ìˆ˜ë‹¨: 2008-01-01ë¡œ í†µì¼
    if baseline is None or (hasattr(baseline, 'isna') and baseline.isna().all()):
        print("   âš ï¸  ê²½ê³ : ì°¸ê°€ì¼(p53) ì»¬ëŸ¼ ì—†ìŒ. ëª¨ë“  ì°¸ê°€ì¼ì„ '2008-01-01'ë¡œ ê°€ì •í•©ë‹ˆë‹¤.")
        print("      (UK Biobank ëª¨ì§‘ ì¤‘ê°„ê°’ ì‚¬ìš©, 2006-2010ë…„)")
        baseline = pd.Series([pd.Timestamp('2008-01-01')] * len(df))
    
    # baselineì„ dfì— ì €ì¥ (ì¤‘ìš”!)
    df['baseline'] = baseline
    
    # Death date
    if death_date_col and death_date_col in df.columns:
        death_date = pd.to_datetime(df[death_date_col], errors='coerce')
    else:
        death_date = None
    
    # Administrative censor date (ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ë‚ ì§œ)
    admin_censor = pd.Timestamp('2024-11-23')  # participant.p42018ì˜ ìµœëŒ€ê°’
    
    # Event ì •ì˜
    df['event'] = dementia_date.notna().astype(int) if dementia_date is not None else 0
    
    # Prevalent case í™•ì¸ (baseline ì´ì „ì— ì´ë¯¸ ì¹˜ë§¤)
    if dementia_date is not None:
        df['is_prevalent'] = (dementia_date <= baseline) & dementia_date.notna()
    else:
        df['is_prevalent'] = False
    
    # Time ê³„ì‚°
    def get_time_event(row):
        baseline_val = row['baseline']
        dementia_val = row['dementia_date']
        death_val = row['death_date'] if death_date is not None else None
        event_val = row['event']
        
        # Prevalent case
        if row['is_prevalent']:
            return -1, -1  # ì œê±° ëŒ€ìƒ
        
        # Baselineì´ ì—†ìœ¼ë©´ ì œì™¸
        if pd.isna(baseline_val):
            return None, None
        
        # Event case: baselineë¶€í„° dementia_dateê¹Œì§€
        if event_val == 1 and pd.notna(dementia_val):
            days = (dementia_val - baseline_val).days
            if days < 0:
                return -1, -1  # Prevalent case
            return 1, max(days, 0.1) / 365.25  # ìµœì†Œ 0.1ë…„
        
        # Censored case: baselineë¶€í„° censor_dateê¹Œì§€
        # ì‚¬ë§ì¼ì´ ìˆìœ¼ë©´ ì‚¬ë§ì¼, ì—†ìœ¼ë©´ admin_censor
        end_date = death_val if (death_val is not None and pd.notna(death_val)) else admin_censor
        end_date = min(end_date, admin_censor)  # ë¯¸ë˜ ë‚ ì§œ ë°©ì§€
        
        days = (end_date - baseline_val).days
        if days < 0:
            return None, None  # ì˜¤ë¥˜
        
        return 0, max(days, 0.1) / 365.25  # ìµœì†Œ 0.1ë…„
    
    # ì»¬ëŸ¼ ì¤€ë¹„ (baselineì€ ì´ë¯¸ ì €ì¥ë¨)
    df['dementia_date'] = dementia_date if dementia_date is not None else pd.Series([None] * len(df))
    if death_date is not None:
        df['death_date'] = death_date
    else:
        df['death_date'] = None
    
    # Time/Event ê³„ì‚°
    results = df.apply(get_time_event, axis=1, result_type='expand')
    df['event_calc'] = results[0]
    df['time_calc'] = results[1]
    
    # ìµœì¢… event/time (prevalent caseëŠ” -1)
    df['event'] = df['event_calc']
    df['time'] = df['time_calc']
    
    return df

def select_alpha_cv_10fold(X, y_surv, alphas, n_folds=10, random_state=42):
    """
    10-fold CV + 1SE ruleë¡œ ìµœì  alpha ì„ íƒ (ë…¼ë¬¸ ë°©ì‹)
    
    Args:
        X: feature matrix
        y_surv: survival array
        alphas: alpha candidates
        n_folds: CV fold ìˆ˜ (ë…¼ë¬¸: 10-fold)
    
    Returns:
        best_alpha: ìµœì  alpha
        mean_scores: í‰ê·  C-index
        std_scores: í‘œì¤€í¸ì°¨
    """
    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)
    cv_scores = []
    
    print(f"   - {n_folds}-fold CV ì§„í–‰ ì¤‘...")
    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):
        X_cv_tr, X_cv_val = X[train_idx], X[val_idx]
        y_cv_tr = Surv.from_arrays(
            event=y_surv['event'][train_idx],
            time=y_surv['time'][train_idx]
        )
        y_cv_val_event = y_surv['event'][val_idx]
        y_cv_val_time = y_surv['time'][val_idx]
        
        # ê° alphaì— ëŒ€í•´ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
        cv_scores_alpha = []
        for alpha in alphas:
            try:
                cox_cv = CoxnetSurvivalAnalysis(
                    alphas=[alpha],
                    l1_ratio=1.0,
                    fit_baseline_model=True,
                    max_iter=1000,
                    tol=1e-6
                )
                cox_cv.fit(X_cv_tr, y_cv_tr)
                
                # Linear predictor ê³„ì‚°
                if cox_cv.coef_.shape[1] > 0:
                    linear_pred = X_cv_val @ cox_cv.coef_[:, 0]
                    # C-index ê³„ì‚°
                    c_index = concordance_index_censored(
                        y_cv_val_event, y_cv_val_time, linear_pred
                    )[0]
                    cv_scores_alpha.append(c_index)
                else:
                    cv_scores_alpha.append(0.5)
            except Exception as e:
                cv_scores_alpha.append(0.5)
        
        cv_scores.append(cv_scores_alpha)
        if fold % 2 == 0:
            print(f"     Fold {fold}/{n_folds} ì™„ë£Œ")
    
    # CV ì ìˆ˜ í‰ê·  ë° í‘œì¤€í¸ì°¨
    cv_scores = np.array(cv_scores)
    mean_scores = np.mean(cv_scores, axis=0)
    std_scores = np.std(cv_scores, axis=0)
    
    # 1SE rule: ìµœëŒ€ C-index - 1 SE
    max_idx = np.argmax(mean_scores)
    max_score = mean_scores[max_idx]
    se = std_scores[max_idx] / np.sqrt(n_folds)  # í‘œì¤€ì˜¤ì°¨
    
    threshold = max_score - se
    
    # thresholdë³´ë‹¤ í° ê°€ì¥ í° alpha ì„ íƒ (ë” ê°„ë‹¨í•œ ëª¨ë¸)
    valid_indices = np.where(mean_scores >= threshold)[0]
    best_alpha_idx = valid_indices[-1] if len(valid_indices) > 0 else max_idx
    
    best_alpha = alphas[best_alpha_idx]
    
    return best_alpha, mean_scores, std_scores

def build_protrs_paper_method(
    baseline_date_col=None,
    death_date_col=None,
    n_folds=10
):
    """
    ë…¼ë¬¸ ë°©ë²•ë¡  ì •í™•íˆ ë”°ë¥´ê¸° - PrRSMDD-ADRD ìƒì„±
    
    Args:
        baseline_date_col: baseline date ì»¬ëŸ¼ëª…
        death_date_col: death date ì»¬ëŸ¼ëª…
        n_folds: CV fold ìˆ˜ (ë…¼ë¬¸: 10-fold)
    """
    print("=" * 70)
    print("PrRSMDD-ADRD ìƒì„± (ë…¼ë¬¸ ë°©ë²•ë¡  ì •í™•íˆ ë”°ë¥´ê¸°)")
    print("=" * 70)
    print("\nğŸ“Œ ë…¼ë¬¸ ë°©ë²•ë¡ :")
    print("   1. Inverse Normal Transformation (INT)")
    print("   2. Prevalent Case ì œê±°")
    print("   3. 10-fold CV + 1SE rule")
    print("   4. LASSO Cox Regression")
    print("   5. C-index í‰ê°€")
    
    # -------------------------
    # 1. ë°ì´í„° ë¡œë“œ ë° ë³‘í•©
    # -------------------------
    print("\n[1/7] ë°ì´í„° ë¡œë“œ ë° ë³‘í•©...")
    df_master = pd.read_parquet(MASTER)
    print(f"   - Master ë°ì´í„°: {len(df_master):,} ìƒ˜í”Œ")
    
    # Outcome ë°ì´í„° ë¡œë“œ (ë” ë§ì€ participant.p42018 ì •ë³´)
    df_outcome = pd.read_csv(OUTCOME_FILE, usecols=['eid', 'participant.p42018'])
    print(f"   - Outcome ë°ì´í„°: {len(df_outcome):,} ìƒ˜í”Œ")
    print(f"   - participant.p42018 ìœ íš¨ê°’: {df_outcome['participant.p42018'].notna().sum():,}ê°œ")
    
    # ë³‘í•© (outcome ë°ì´í„°ì˜ ë” ë§ì€ ì •ë³´ ì‚¬ìš©)
    df = df_master.merge(df_outcome, on='eid', how='left', suffixes=('', '_new'))
    
    # participant.p42018 ìš°ì„ ìˆœìœ„: ìƒˆ ë°ì´í„° > ê¸°ì¡´ ë°ì´í„°
    if 'participant.p42018_new' in df.columns:
        df['participant.p42018'] = df['participant.p42018_new'].fillna(df['participant.p42018'])
        df = df.drop(columns=['participant.p42018_new'])
    
    print(f"   - ë³‘í•© í›„: {len(df):,} ìƒ˜í”Œ")
    print(f"   - participant.p42018 ìœ íš¨ê°’: {df['participant.p42018'].notna().sum():,}ê°œ")
    
    # -------------------------
    # 2. Time/Event ê³„ì‚° ë° Prevalent Case ì œê±°
    # -------------------------
    print("\n[2/7] Time/Event ê³„ì‚° ë° Prevalent Case ì œê±°...")
    df = calculate_survival_time_paper_method(df, baseline_date_col, death_date_col)
    
    # Prevalent case ë° ì˜¤ë¥˜ ë°ì´í„° ì œê±°
    before = len(df)
    df_clean = df[(df['event'] != -1) & (df['time'] > 0) & df['time'].notna()].copy()
    n_prevalent = (df['event'] == -1).sum()
    
    print(f"   - Prevalent case ì œê±°: {n_prevalent:,}ê°œ")
    print(f"   - ìµœì¢… ë¶„ì„ ë°ì´í„°: {len(df_clean):,} ìƒ˜í”Œ (ì œê±° ì „: {before:,})")
    print(f"   - Event (ì¹˜ë§¤): {df_clean['event'].sum():,} ({df_clean['event'].mean()*100:.2f}%)")
    print(f"   - Censored: {(df_clean['event']==0).sum():,}")
    print(f"   - Time ë²”ìœ„: {df_clean['time'].min():.2f} ~ {df_clean['time'].max():.2f}ë…„")
    
    # -------------------------
    # 3. ë‹¨ë°±ì§ˆ ì»¬ëŸ¼ ì¶”ì¶œ
    # -------------------------
    print("\n[3/7] ë‹¨ë°±ì§ˆ ì»¬ëŸ¼ ì¶”ì¶œ...")
    protein_cols = get_protein_cols(df_clean)
    print(f"   - ë‹¨ë°±ì§ˆ ì»¬ëŸ¼ ìˆ˜: {len(protein_cols):,}")
    
    # -------------------------
    # 4. Train/Test split
    # -------------------------
    print("\n[4/7] Train/Test split...")
    X = df_clean[protein_cols].copy()
    y_event = df_clean['event'].values
    y_time = df_clean['time'].values
    
    X_tr, X_te, event_tr, event_te, time_tr, time_te = train_test_split(
        X, y_event, y_time,
        test_size=0.2,
        random_state=42,
        stratify=y_event
    )
    
    print(f"   - Train: {len(X_tr):,} ìƒ˜í”Œ (event: {event_tr.sum():,})")
    print(f"   - Test: {len(X_te):,} ìƒ˜í”Œ (event: {event_te.sum():,})")
    
    # -------------------------
    # 5. ë°ì´í„° ì „ì²˜ë¦¬: Imputation + INT
    # -------------------------
    print("\n[5/7] ë°ì´í„° ì „ì²˜ë¦¬ (Imputation + INT)...")
    imputer = SimpleImputer(strategy="median")
    
    # Imputation
    X_tr_imputed = imputer.fit_transform(X_tr)
    X_te_imputed = imputer.transform(X_te)
    
    # Inverse Normal Transformation (ë…¼ë¬¸ ë°©ì‹)
    print("   - Inverse Normal Transformation ì ìš© ì¤‘...")
    X_tr_int = apply_inverse_normal_transform(X_tr_imputed)
    X_te_int = apply_inverse_normal_transform(X_te_imputed)
    
    # NaN ì²˜ë¦¬ (INT í›„ì—ë„ ìˆì„ ìˆ˜ ìˆìŒ)
    X_tr_int = np.nan_to_num(X_tr_int, nan=0.0)
    X_te_int = np.nan_to_num(X_te_int, nan=0.0)
    
    # ìˆ˜ì¹˜ì  ì•ˆì •ì„±
    X_tr_int = np.clip(X_tr_int, -10, 10)
    X_te_int = np.clip(X_te_int, -10, 10)
    
    print("   - INT ì™„ë£Œ")
    
    # -------------------------
    # 6. 10-fold CVë¡œ ìµœì  alpha ì„ íƒ
    # -------------------------
    print("\n[6/7] 10-fold CVë¡œ ìµœì  alpha ì„ íƒ (1SE rule)...")
    y_tr_surv = Surv.from_arrays(event=event_tr.astype(bool), time=time_tr)
    alphas = np.logspace(-4, 1, 100)  # ë…¼ë¬¸ê³¼ ìœ ì‚¬í•œ ë²”ìœ„
    
    best_alpha, mean_scores, std_scores = select_alpha_cv_10fold(
        X_tr_int,
        {'event': event_tr.astype(bool), 'time': time_tr},
        alphas,
        n_folds=n_folds
    )
    
    print(f"   - ìµœì  alpha: {best_alpha:.6f}")
    print(f"   - ìµœëŒ€ C-index: {mean_scores.max():.4f}")
    best_alpha_idx = np.where(alphas == best_alpha)[0][0]
    print(f"   - ì„ íƒëœ alphaì˜ C-index: {mean_scores[best_alpha_idx]:.4f} Â± {std_scores[best_alpha_idx]:.4f}")
    
    # -------------------------
    # 7. ìµœì  alphaë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ
    # -------------------------
    print("\n[7/7] ìµœì  alphaë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ...")
    
    cox_lasso = CoxnetSurvivalAnalysis(
        alphas=[best_alpha],
        l1_ratio=1.0,
        fit_baseline_model=True,
        max_iter=1000,
        tol=1e-6
    )
    
    cox_lasso.fit(X_tr_int, y_tr_surv)
    
    # ì„ íƒëœ ë‹¨ë°±ì§ˆ í™•ì¸
    coefs = cox_lasso.coef_[:, 0]
    selected_proteins = np.where(np.abs(coefs) > 1e-6)[0]
    print(f"   - ì„ íƒëœ ë‹¨ë°±ì§ˆ ìˆ˜: {len(selected_proteins):,} / {len(protein_cols):,}")
    
    # -------------------------
    # 8. ProtRS ê³„ì‚° ë° í‰ê°€
    # -------------------------
    print("\n[8/8] ProtRS ê³„ì‚° ë° í‰ê°€...")
    
    # ì „ì²´ ë°ì´í„°ë¡œ ProtRS ê³„ì‚°
    X_all_numeric = df_clean[protein_cols].select_dtypes(include=[np.number])
    X_all_imputed = imputer.transform(X_all_numeric)
    X_all_int = apply_inverse_normal_transform(X_all_imputed)
    X_all_int = np.nan_to_num(X_all_int, nan=0.0)
    X_all_int = np.clip(X_all_int, -10, 10)
    
    X_all_selected = X_all_int[:, selected_proteins]
    protrs_all = X_all_selected @ coefs[selected_proteins]
    
    # Test set ProtRS
    X_te_selected = X_te_int[:, selected_proteins]
    protrs_te = X_te_selected @ coefs[selected_proteins]
    
    # C-index ê³„ì‚°
    c_index = concordance_index_censored(
        event_te.astype(bool),
        time_te,
        protrs_te
    )[0]
    
    print(f"   - C-index (test): {c_index:.4f}")
    print(f"   - ë…¼ë¬¸ ê²°ê³¼: C statistic = 0.84")
    
    # ê²°ê³¼ ì €ì¥
    df_protrs = pd.DataFrame({
        "eid": df_clean["eid"].values,
        "ProtRS": protrs_all,
        "target_dementia": df_clean["target_dementia"].values,
        "target_age": df_clean["target_age"].values,
        "event": df_clean["event"].values,
        "time": df_clean["time"].values
    })
    
    df_protrs.to_parquet(OUT_PROTRS, index=False)
    print(f"   - ProtRS ì €ì¥: {OUT_PROTRS}")
    
    # ì„ íƒëœ ë‹¨ë°±ì§ˆ ë° ê°€ì¤‘ì¹˜ ì €ì¥ (View A ì¸ì½”ë”ìš©)
    selected_protein_names = [protein_cols[i] for i in selected_proteins]
    df_weights = pd.DataFrame({
        "protein": selected_protein_names,
        "weight": coefs[selected_proteins]
    }).sort_values("weight", key=abs, ascending=False)
    
    df_weights.to_csv(OUT_WEIGHTS, index=False)
    print(f"   - ê°€ì¤‘ì¹˜ ì €ì¥: {OUT_WEIGHTS}")
    
    # ì‹œê°í™”
    fig, axes = plt.subplots(2, 2, figsize=(14, 12))
    
    # 1. ProtRS ë¶„í¬
    ax = axes[0, 0]
    ax.hist(protrs_all, bins=50, alpha=0.7, edgecolor='black')
    ax.set_xlabel("ProtRS")
    ax.set_ylabel("Frequency")
    ax.set_title("ProtRS Distribution")
    ax.grid(True, alpha=0.3)
    
    # 2. ProtRS by Event
    ax = axes[0, 1]
    ax.boxplot([protrs_all[df_clean['event']==0], protrs_all[df_clean['event']==1]],
               labels=['No Dementia', 'Dementia'])
    ax.set_ylabel("ProtRS")
    ax.set_title("ProtRS by Dementia Status")
    ax.grid(True, alpha=0.3)
    
    # 3. CV scores
    ax = axes[1, 0]
    ax.plot(alphas, mean_scores, 'b-', label='Mean C-index')
    ax.fill_between(alphas, mean_scores - std_scores, mean_scores + std_scores, alpha=0.2)
    ax.axvline(best_alpha, color='r', linestyle='--', label=f'Best alpha ({best_alpha:.4f})')
    ax.set_xscale('log')
    ax.set_xlabel("Alpha")
    ax.set_ylabel("C-index")
    ax.set_title("10-fold CV Scores for Alpha Selection")
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 4. ì„ íƒëœ ë‹¨ë°±ì§ˆ ê³„ìˆ˜
    ax = axes[1, 1]
    top_proteins = df_weights.head(15)
    ax.barh(range(len(top_proteins)), top_proteins['weight'].values)
    ax.set_yticks(range(len(top_proteins)))
    ax.set_yticklabels(top_proteins['protein'].values)
    ax.set_xlabel("Coefficient")
    ax.set_title("Top Selected Proteins")
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(OUT_PLOT, dpi=300, bbox_inches='tight')
    print(f"   - ì‹œê°í™” ì €ì¥: {OUT_PLOT}")
    
    print("\n" + "=" * 70)
    print("PrRSMDD-ADRD í†µê³„ ìš”ì•½")
    print("=" * 70)
    print(f"ProtRS í‰ê· : {protrs_all.mean():.2f}")
    print(f"ProtRS í‘œì¤€í¸ì°¨: {protrs_all.std():.2f}")
    print(f"C-index (test): {c_index:.4f}")
    print(f"ì„ íƒëœ ë‹¨ë°±ì§ˆ ìˆ˜: {len(selected_proteins):,}")
    print(f"Prevalent case ì œê±°: {n_prevalent:,}ê°œ")
    
    print("\nâœ… PrRSMDD-ADRD ìƒì„± ì™„ë£Œ!")
    print(f"\nğŸ“ ì¶œë ¥ íŒŒì¼:")
    print(f"   - ProtRS: {OUT_PROTRS}")
    print(f"   - ê°€ì¤‘ì¹˜ (View Aìš©): {OUT_WEIGHTS}")
    print(f"   - ì‹œê°í™”: {OUT_PLOT}")
    
    return df_protrs, df_weights

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='PrRSMDD-ADRD ìƒì„± (ë…¼ë¬¸ ë°©ë²•ë¡ )')
    parser.add_argument('--baseline-col', type=str, default=None,
                        help='Baseline date ì»¬ëŸ¼ëª…')
    parser.add_argument('--death-col', type=str, default=None,
                        help='Death date ì»¬ëŸ¼ëª…')
    parser.add_argument('--n-folds', type=int, default=10,
                        help='CV fold ìˆ˜ (ê¸°ë³¸: 10)')
    
    args = parser.parse_args()
    
    try:
        df_protrs, df_weights = build_protrs_paper_method(
            baseline_date_col=args.baseline_col,
            death_date_col=args.death_col,
            n_folds=args.n_folds
        )
    except ImportError as e:
        print(f"\nâŒ í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("\ní•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜:")
        print("  pip install scikit-survival scipy")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
