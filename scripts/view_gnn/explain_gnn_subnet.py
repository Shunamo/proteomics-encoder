"""
GNN-SubNet: Model Explanation & Disease Subnetwork Detection

í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬:
1. Model-wide explanations
2. Disease subnetwork detection
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import torch
import torch.nn as nn
from torch_geometric.loader import DataLoader
from sklearn.model_selection import train_test_split

from src.data.graph_dataset import GraphDataLoader
from src.view_gnn.models.graph_classifier import GraphClassifier
from src.view_gnn.explainer.gnn_explainer import ModifiedGNNExplainer
from src.view_gnn.community.community_detection import detect_disease_subnetworks, get_subnetwork_proteins


def main():
    print("=" * 70)
    print("GNN-SubNet: Model Explanation & Subnetwork Detection")
    print("=" * 70)
    
    # 1. ë°ì´í„° ë¡œë“œ (í•™ìŠµê³¼ ë™ì¼í•œ ë°©ì‹)
    print("\n[1/4] ë°ì´í„° ë¡œë“œ...")
    master_file = "../../data/ukb/ukb_usable_master.parquet"
    df = pd.read_parquet(master_file)
    
    # ë‹¨ë°±ì§ˆ ì»¬ëŸ¼ ì¶”ì¶œ
    exclude_cols = ["eid", "sex", "target_age", "target_dementia", "participant.p42018"]
    protein_cols = [c for c in df.columns 
                   if c not in exclude_cols 
                   and not c.startswith("pc__")
                   and not c.startswith("assess__")
                   and not c.startswith("online__")]
    
    # ë°ì´í„° ì •ê·œí™” (í•™ìŠµê³¼ ë™ì¼)
    from sklearn.preprocessing import StandardScaler
    print("   - ë°ì´í„° ì •ê·œí™” ì ìš©...")
    scaler = StandardScaler()
    df[protein_cols] = scaler.fit_transform(df[protein_cols])
    
    # 2. Graph ë°ì´í„° ìƒì„±
    print("\n[2/4] Graph ë°ì´í„° ìƒì„±...")
    score_threshold = 700
    loader = GraphDataLoader(score_threshold=score_threshold)
    
    # í•™ìŠµê³¼ ë™ì¼í•œ ìƒ˜í”Œë§
    target_total = 10000
    df_pos = df[df['target_dementia'] == 1]
    df_neg_all = df[df['target_dementia'] == 0]
    n_neg = min(target_total - len(df_pos), len(df_neg_all))
    df_neg = df_neg_all.sample(n=n_neg, random_state=42)
    df_sample = pd.concat([df_pos, df_neg]).sample(frac=1, random_state=42).reset_index(drop=True)
    
    graphs = loader.create_graph_dataset(
        df_sample,
        protein_cols,
        label_col='target_dementia',
        eid_col='eid'
    )
    
    # Train/Test split (í•™ìŠµê³¼ ë™ì¼í•œ ë°©ì‹)
    labels = [g.y.item() for g in graphs]
    train_graphs, test_graphs = train_test_split(
        graphs,
        test_size=0.2,
        random_state=42,
        stratify=labels
    )
    
    print(f"   - Test graphs: {len(test_graphs):,}ê°œ")
    
    # 3. ëª¨ë¸ ë¡œë“œ
    print("\n[3/4] ëª¨ë¸ ë¡œë“œ...")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    model = GraphClassifier(
        input_dim=1,
        hidden_dim=64,
        embedding_dim=256,
        num_layers=2,
        num_classes=2,
        pooling='mean',
        dropout=0.2
    ).to(device)
    
    model.load_state_dict(torch.load('../../data/gnn_subnet_best_model.pt'))
    model.eval()
    print("   âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # 4. Model-wide Explanations & Subnetwork Detection
    print("\n[4/4] Model-wide Explanations & Subnetwork Detection...")
    
    explainer = ModifiedGNNExplainer(model, epochs=100, lr=0.01)
    
    # Dementia ìƒ˜í”Œë§Œ ì‚¬ìš©
    dementia_graphs = [g for g in test_graphs if g.y.item() == 1]
    print(f"   - Dementia ìƒ˜í”Œ: {len(dementia_graphs):,}ê°œ")
    
    # ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•˜ì—¬ í‰ê·  ê³„ì‚°
    n_runs = 5
    print(f"   - Explainer ì‹¤í–‰ íšŸìˆ˜: {n_runs}íšŒ")
    
    all_node_imps = []
    all_edge_imps = []
    
    for run_idx in range(n_runs):
        print(f"   - Run {run_idx + 1}/{n_runs}...", end=' ')
        
        avg_node_imp, avg_edge_imp = explainer.explain_model_wide(
            dementia_graphs,
            target_class=1,
            batch_size=32
        )
        
        all_node_imps.append(avg_node_imp.cpu())
        all_edge_imps.append(avg_edge_imp.cpu())
        print("ì™„ë£Œ")
    
    # í‰ê·  ê³„ì‚°
    avg_node_imp = torch.stack(all_node_imps).mean(dim=0).to(device)
    avg_edge_imp = torch.stack(all_edge_imps).mean(dim=0).to(device)
    
    print(f"   - Node importance shape: {avg_node_imp.shape}")
    print(f"   - Edge importance shape: {avg_edge_imp.shape}")
    
    # Disease subnetwork detection
    first_graph = graphs[0]
    communities = detect_disease_subnetworks(
        first_graph.edge_index,
        avg_node_imp,
        avg_edge_imp,
        original_edge_weights=first_graph.edge_attr if hasattr(first_graph, 'edge_attr') else None,
        top_k=10,
        resolution=1.0
    )
    
    print(f"\n   âœ… ë°œê²¬ëœ Disease Subnetworks: {len(communities)}ê°œ")
    
    # Node mapping
    node_to_protein = loader.get_node_mapping()
    
    # ë‹¨ë°±ì§ˆ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
    subnetworks = get_subnetwork_proteins(communities, node_to_protein)
    
    # ê²°ê³¼ ì €ì¥
    results = []
    for i, subnet in enumerate(subnetworks):
        results.append({
            'subnetwork_id': i + 1,
            'num_proteins': subnet['size'],
            'importance': subnet['importance'],
            'proteins': ', '.join(subnet['proteins'][:20])
        })
    
    df_results = pd.DataFrame(results)
    df_results.to_csv('../../data/gnn_subnet_disease_subnetworks.csv', index=False)
    
    print("\n" + "=" * 70)
    print("âœ… Explanation & Subnetwork Detection ì™„ë£Œ!")
    print("=" * 70)
    print("\nğŸ“ ì¶œë ¥ íŒŒì¼:")
    print("   - Disease Subnetworks: ../../data/gnn_subnet_disease_subnetworks.csv")
    print("\nğŸ“Š Top 5 Disease Subnetworks:")
    print(df_results.head().to_string(index=False))


if __name__ == "__main__":
    main()
