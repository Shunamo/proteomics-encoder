#!/usr/bin/env python3
import os
import pandas as pd
import numpy as np

def build_ukb_usable_datasets(
    file_prot="../../data/ukb/ukb_ppp_instance0.csv",
    file_meta="../../data/ukb/ukb_cog_cov_ppp.csv",
    file_outcome="../../data/ukb/ukb_cog_cov_master_plus_dementia_outcome.csv",
    out_master="../../data/ukb/ukb_usable_master.parquet",
    out_cases="../../data/ukb/ukb_dementia_cases.parquet",
):
    print("ğŸš€ UKB usable dataset build start (Update for Survival Analysis)")
    
    # ---------------------------------------------------------
    # 0) íŒŒì¼ ì¡´ì¬ í™•ì¸
    # ---------------------------------------------------------
    for fp in [file_prot, file_meta, file_outcome]:
        if not os.path.exists(fp):
            raise FileNotFoundError(f"íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {fp}")

    # ---------------------------------------------------------
    # 1) Proteomics (Anchor)
    # ---------------------------------------------------------
    print("[1/6] Loading proteomics (anchor)...")
    df_prot = pd.read_csv(file_prot)
    if "eid" not in df_prot.columns:
        raise ValueError("PROT íŒŒì¼ì— 'eid'ê°€ ì—†ìŠµë‹ˆë‹¤.")
    print(f"   - PROT rows: {len(df_prot):,}, cols: {df_prot.shape[1]:,}")

    # ---------------------------------------------------------
    # 2) META: p53(ì°¸ê°€ì¼), p40000(ì‚¬ë§ì¼), p21003(ë‚˜ì´), Sex, PCs
    # ---------------------------------------------------------
    print("[2/6] Loading metadata (Dates, Age, Sex, PCs)...")
    
    # ì¤‘ìš”: p53(ì°¸ê°€ì¼)ê³¼ p40000(ì‚¬ë§ì¼)ì„ ë°˜ë“œì‹œ ê°€ì ¸ì™€ì•¼ í•¨
    # íŒŒì¼ë§ˆë‹¤ ì»¬ëŸ¼ëª…ì´ p53, p53_i0 ë“±ìœ¼ë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ì²´í¬ ë¡œì§ ì¶”ê°€
    possible_date_cols = ["p53", "p53_i0", "p40000", "p40000_i0", "p40000_i1"] 
    base_cols_wanted = ["eid", "p31", "p21003_i0"] + [f"pc__p22009_a{i}" for i in range(1, 11)]
    
    # í—¤ë” ë¯¸ë¦¬ ì½ê¸°
    meta_header = pd.read_csv(file_meta, nrows=0).columns.tolist()
    
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    real_cols = [c for c in base_cols_wanted if c in meta_header]
    date_cols = [c for c in possible_date_cols if c in meta_header]
    
    use_cols = list(set(real_cols + date_cols)) # ì¤‘ë³µì œê±°
    
    print(f"   - Loading cols: {len(use_cols)} columns including dates")
    df_meta = pd.read_csv(file_meta, usecols=use_cols)

    # ì»¬ëŸ¼ëª… í‘œì¤€í™” (ë¶„ì„í•˜ê¸° í¸í•˜ê²Œ)
    # p53(ì°¸ê°€ì¼) ì°¾ê¸°
    col_attend = next((c for c in ["p53_i0", "p53"] if c in df_meta.columns), None)
    # p40000(ì‚¬ë§ì¼) ì°¾ê¸° (ë³´í†µ ì¸ìŠ¤í„´ìŠ¤ 0, 1 ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ë¨. ì—¬ê¸°ì„  ìš°ì„ ìˆœìœ„ ë‘ )
    col_death = next((c for c in ["p40000_i0", "p40000", "p40000_i1"] if c in df_meta.columns), None)

    if col_attend: df_meta = df_meta.rename(columns={col_attend: "date_attend"})
    if col_death: df_meta = df_meta.rename(columns={col_death: "date_death"})
    if "p21003_i0" in df_meta.columns: df_meta = df_meta.rename(columns={"p21003_i0": "age"})
    if "p31" in df_meta.columns: df_meta = df_meta.rename(columns={"p31": "sex"})

    if "date_attend" not in df_meta.columns:
        raise ValueError("âš ï¸ ì¹˜ëª…ì  ì˜¤ë¥˜: META íŒŒì¼ì— ì°¸ê°€ì¼(p53)ì´ ì—†ìŠµë‹ˆë‹¤. Cox ë¶„ì„ ë¶ˆê°€!")

    # ---------------------------------------------------------
    # 3) OUTCOME: Dementia Date
    # ---------------------------------------------------------
    print("[3/6] Loading outcome (dementia date)...")
    out_cols = ["eid", "participant.p42018"] # ìƒˆë¡œ ì°¾ì€ íŒŒì¼ ê¸°ì¤€
    df_out = pd.read_csv(file_outcome, usecols=out_cols)
    df_out = df_out.rename(columns={"participant.p42018": "date_dementia"})

    # ---------------------------------------------------------
    # 4) MERGE & DATE PARSING
    # ---------------------------------------------------------
    print("[4/6] Merging & Parsing dates...")
    df_master = df_prot.merge(df_meta, on="eid", how="inner")
    df_master = df_master.merge(df_out, on="eid", how="left")
    
    # ë‚ ì§œ ë³€í™˜ (ì—ëŸ¬ ë°œìƒ ì‹œ NaT ì²˜ë¦¬)
    for col in ["date_attend", "date_death", "date_dementia"]:
        if col in df_master.columns:
            df_master[col] = pd.to_datetime(df_master[col], errors="coerce")

    # ---------------------------------------------------------
    # 5) âœ¨ CRITICAL: Survival Data Creation (Event & Time)
    # ---------------------------------------------------------
    print("[5/6] Calculating Event & Time for Cox Regression...")
    
    # ì—°êµ¬ ì¢…ë£Œì¼ (Censor Date): ë°ì´í„° ì¶”ì¶œ ì‹œì  (ê°€ì¥ ìµœê·¼ ë‚ ì§œ)
    # ì•ˆì „í•˜ê²Œ 2024-01-01 í˜¹ì€ ë°ì´í„° ë‚´ ìµœëŒ€ê°’ ì‚¬ìš©
    CENSOR_DATE = pd.Timestamp("2024-11-23") 
    
    def calculate_survival(row):
        start = row["date_attend"]
        event_date = row["date_dementia"]
        death_date = row.get("date_death", pd.NaT) # ì—†ì„ ìˆ˜ë„ ìˆìŒ
        
        if pd.isna(start): return -99, -99 # ì°¸ê°€ì¼ ëª¨ë¥´ë©´ ì‚­ì œ
        
        # A. Prevalent Case (ì°¸ê°€ ì „ì— ì´ë¯¸ ë°œë³‘) -> ì‚­ì œ ëŒ€ìƒ(-1)
        if pd.notna(event_date) and event_date <= start:
            return -1, -1
        
        # B. Incident Case (ì¶”ì  ì¤‘ ë°œë³‘) -> Event=1
        if pd.notna(event_date):
            days = (event_date - start).days
            return 1, days / 365.25
            
        # C. Censored Case (ë°œë³‘ ì•ˆ í•¨) -> Event=0
        # ì¢…ë£Œ ì‹œì  = ì‚¬ë§ì¼ vs ì—°êµ¬ì¢…ë£Œì¼ ì¤‘ ë¹ ë¥¸ ê²ƒ
        end_date = CENSOR_DATE
        if pd.notna(death_date):
            end_date = min(death_date, CENSOR_DATE)
            
        days = (end_date - start).days
        # ë‚ ì§œ ì˜¤ë¥˜ë¡œ ìŒìˆ˜ ë‚˜ì˜¤ë©´ 0.1ë…„ ì²˜ë¦¬
        return 0, max(days, 30) / 365.25 

    # ê³„ì‚° ì ìš©
    surv_res = df_master.apply(calculate_survival, axis=1, result_type="expand")
    df_master["event"] = surv_res[0]
    df_master["time"] = surv_res[1]

    # Prevalent Case (-1) ë° ì˜¤ë¥˜ ë°ì´í„° ì‚­ì œ
    n_total = len(df_master)
    df_master = df_master[df_master["event"] != -1]
    df_master = df_master[df_master["time"] > 0]
    df_master = df_master[df_master["event"] != -99]
    
    print(f"   - Removed Prevalent/Invalid cases: {n_total - len(df_master):,}")
    print(f"   - Final Cohort: {len(df_master):,}")
    print(f"   - Incident Dementia Cases (Event=1): {df_master['event'].sum():,}")

    # ---------------------------------------------------------
    # 6) Save
    # ---------------------------------------------------------
    print("[6/6] Saving outputs...")
    # ì»¬ëŸ¼ ì •ë¦¬ (í•„ìš”í•œ ê²ƒ ìœ„ì£¼ë¡œ ì •ë ¬)
    cols_order = ["eid", "event", "time", "age", "sex", "date_attend", "date_dementia"] 
    # ë‚˜ë¨¸ì§€(ë‹¨ë°±ì§ˆ ë“±) ë’¤ì— ë¶™ì´ê¸°
    cols_rest = [c for c in df_master.columns if c not in cols_order]
    df_master = df_master[cols_order + cols_rest]
    
    df_master.to_parquet(out_master, index=False)
    
    # Event=1 ì¸ ì‚¬ëŒë§Œ ë”°ë¡œ ì €ì¥ (ë¶„ì„ìš©)
    df_cases = df_master[df_master["event"] == 1].copy()
    df_cases.to_parquet(out_cases, index=False)

    print("\nâœ… DONE")
    print(f" - Master saved: {os.path.abspath(out_master)}")
    print(f" - Cases saved : {os.path.abspath(out_cases)}")

    return df_master

if __name__ == "__main__":
    build_ukb_usable_datasets()